---
title: "clean_rmd"
author: "Naren Akurati"
date: "7/5/2018"
output: html_document
---

##Preliminary Analysis
```{r, warning = FALSE}
Sys.setenv(LANG = "en")
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
```

Let's first bring in the data here. We're looking at all the cards from the GTX 280 to the current GTX 1080
```{r}
xx80 <- read.csv("xx80.csv", sep = ";")
xx80
```

Our most important metrics that are going to help us here are transistor density, cuda core count, core speed, and floating point performance. These tend to be positively correlated with the overall performance of a graphics card, whereas something like memory speed or bus size really depends on the nature of the current architecture.
```{r}
p1 <- ggplot(xx80, aes(x = as.Date(launch), y = core_speed)) + geom_point() + geom_smooth(se=FALSE) + labs(x = "time", y = "core clock speed")
p2 <- ggplot(xx80, aes(x = as.Date(launch), y = cuda_cores)) + geom_point() + geom_smooth(se=FALSE) + labs(x = "time", y = "cuda core count")
p4 <- ggplot(xx80, aes(x = as.Date(launch), y = processing_power_single)) + geom_point() + geom_smooth(se=FALSE) + labs(x = "time", y = "floating point perf")
grid.arrange(p2,p1,p4, ncol = 3, nrow =2)
```

However, one metric is very important for gauging raw computer performance and that's transistor density. Let's create a vector for transistor density and rewrite it in terms of transistors per square inch.
```{r}
transistor_density <- xx80$transistors_millions/xx80$die_size
scaled_transistor_density <- xx80$transistors_millions*1000000/xx80$die_size*0.00155

kable(data.frame("card" = xx80$ï..model, "transistor_denisty" = scaled_transistor_density))

#moore's predicted transistor density
moore_predicted_scaled_transistory_density <- rep(scaled_transistor_density[1], 9) * c(1,2,4,8,16,32,64,128,256)
moore_predicted_scaled_transistory_density

moore_dates <- c("2009-01-08", "2010-07-08", "2012-01-08", "2012-07-08", "2014-01-08", "2015-07-08", "2017-01-08", "2018-07-08", "2020-01-08")

transistor_df <- data.frame("date" = c(as.Date(xx80$launch), as.Date(moore_dates)), "transistors" = c(scaled_transistor_density, moore_predicted_scaled_transistory_density), "type" = c(rep("real", 7), rep("moore", 9))) 
transistor_df

transistor_df_subset <- transistor_df[1:7,]
transistor_df_subset

nvidia_transistors <- data.frame("date" = as.Date(xx80$launch), "transistors" = scaled_transistor_density)
moore_transistors <- data.frame("date" = as.Date(moore_dates), "transistors" = moore_predicted_scaled_transistory_density)

nvidia_transistor_model <- lm(sqrt(transistors) ~ date, data = nvidia_transistors)
summary(nvidia_transistor_model)

nvidia_transistor_model2 <- lm(transistors ~ date, data = nvidia_transistors)
summary(nvidia_transistor_model2)

moore_transistor_model <- lm(log(transistors) ~ date, data = moore_transistors)
summary(moore_transistor_model)

library(car)
powerTransform(nvidia_transistors[,2])

#predicted performance boost by transistor density through nvidia linear model
predict(nvidia_transistor_model2, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")/nvidia_transistors[7,2]

#predicted performance boost by transistor density through nvidia transformed model
predict(nvidia_transistor_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")^2/nvidia_transistors[7,2]

#predicted performance boost by transistor density through moore's law
#starting point for moore's law is gtx 280
exp(predict(moore_transistor_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response"))/nvidia_transistors[7,2]

ggplot(transistor_df, aes(x = date, y = transistors, color = type)) + geom_point() + geom_smooth(se=FALSE) + geom_point(aes(x=as.Date("2018-08-01"), y=predict(nvidia_transistor_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")^2), shape = 16, color = "black", size = 2) + geom_point(aes(x=as.Date("2018-08-01"), y=predict(nvidia_transistor_model2, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")), shape = 16, color = "black", size = 2) + geom_point(aes(x=as.Date("2018-08-01"), y=exp(predict(moore_transistor_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response"))), color = "black", size = 2) + xlim(as.Date("2009-01-08"), as.Date("2018-08-02"))

ggplot(transistor_df_subset, aes(x = date, y = transistors)) + geom_point() + geom_smooth(se=FALSE) + geom_point(aes(x=as.Date("2018-08-01"), y=predict(nvidia_transistor_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")^2), shape = 16, color = "black", size = 2) + geom_point(aes(x=as.Date("2018-08-01"), y=predict(nvidia_transistor_model2, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")), shape = 16, color = "black", size = 2)


```

##Bringing in Synthetic benchmarks
```{r, warning = FALSE}
#3DMark Graphics scores pulled from 3dmark site
xx80$threedmark_score <- c(NA, 3649, 4952, 7672, 10490, 13898, 21787)

#Battlefield1 scores pulled from techspot site
xx80$battlefield1 <- c(NA, NA, NA, 53 , 68 , 97 , 151)

bench <- data.frame("card" = rep(c(280, 480, 580, 680, 780, 980, 1080),3), "score" = c(xx80$processing_power_single, xx80$threedmark_score, xx80$battlefield1), "category" = c(rep("teraflops", 7), rep("3d_mark_score", 7), rep("battlefield1_fps", 7)), "date" = rep(xx80$launch, 3))

threedmark_data <- data.frame("date" = as.Date(xx80$launch), "score" = xx80$threedmark_score)
tflop_data <- data.frame("date" = as.Date(xx80$launch), "score" = xx80$processing_power_single)

threedmark_model <- lm(score ~ date, threedmark_data)
summary(threedmark_model)

tflop_model <- lm(score ~ date, tflop_data)
summary(tflop_model)

powerTransform(tflop_data[,2])

tflop_model2 <- lm(sqrt(score) ~ date, tflop_data)
summary(tflop_model2)

predict(tflop_model, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")

predict(tflop_model2, newdata = data.frame("date" = as.Date("2018-08-01")), type = "response")^2

ggplot(xx80, aes(x = as.Date(launch), y = processing_power_single)) + geom_point() + geom_smooth(se=FALSE, color = "#619CFF")
ggplot(xx80, aes(x = as.Date(launch), y = threedmark_score)) + geom_point() + geom_smooth(se=FALSE, color = "#F8766D")
ggplot(xx80, aes(x = as.Date(launch), y = battlefield1)) + geom_point() + geom_smooth(se=FALSE, color = "#00BA38")

#Looking at percentage increase
xx80$threedmark_percentage <- xx80$threedmark_score/c(1, xx80$threedmark_score[1:6])
xx80$processing_power_single_percentage <- xx80$processing_power_single/c(NA, xx80$processing_power_single[1:6])
xx80$battlefield1_percentage <- xx80$battlefield1/c(1, xx80$battlefield1[1:6])

bench_percentage <- data.frame("card" = rep(c(280, 480, 580, 680, 780, 980, 1080),3), "percentage_imporvement" = c(xx80$processing_power_single_percentage, xx80$threedmark_percentage, xx80$battlefield1_percentage), "category" = c(rep("teraflops", 7), rep("3d_mark_score", 7), rep("battlefield1_fps", 7)), "date" = rep(xx80$launch, 3))

bench_percentage

ggplot(bench_percentage, aes(x = as.Date(date), y = percentage_imporvement, color = category)) + geom_point() + geom_smooth(se=FALSE)

as.Date(as.character(xx80$launch[2:7])) - as.Date(as.character(xx80$launch[1:6]))
mean(as.Date(as.character(xx80$launch[2:7])) - as.Date(as.character(xx80$launch[1:6])))
as.Date(as.character(xx80$launch[7])) - as.Date(as.character("2018-07-05"))
830/440
```

Seeing above, we can separate the releases between BIG and SMALL performance improvments. GTX 480, 680, and 1080 were BIG performance improvements. GTX 580, 780, and 980 were SMALL performance improvements. Given the time since the last release is 1.88 times greater than the average time in between releases, we can assume we are in for a significant performance boost with this next generation.
```{r}
xx80$processing_power_single_percentage
mean(xx80$processing_power_single_percentage[c(2,4,7)])
xx80$processing_power_single[7] * mean(xx80$processing_power_single_percentage[c(2,4,7)])
```

##Bringing in Game Benchmarks
Won't be looking too much into gaming benchmarks as the people over at Anandtech, Techspot, and PCPer have this down with great detail.
```{r}
#Have already added in Battlefield 1 benchmarks at 1080p
xx80$battlefield1

#Tech spot aggregated game performance
xx80$average_game_perf_1080p <- c(NA, 21, 24, 40, 56, 77, 127)
xx80$average_game_perf_1600p <- c(NA, 30, 35, 53, 71, 109, 161)

game_synthetic_scores <- data.frame("date" = as.Date(xx80$launch), "game_perf_1080p" = xx80$average_game_perf_1080p, "game_perf_1600p" = xx80$average_game_perf_1600p, "tflop" = xx80$processing_power_single, "threedmark" = xx80$threedmark_score)

game_synthetic_1080p_model <- lm(game_perf_1080p ~ tflop, data = game_synthetic_scores)
summary(game_synthetic_1080p_model)

game_synthetic_1600p_model <- lm(game_perf_1600p ~ tflop, data = game_synthetic_scores)
summary(game_synthetic_1600p_model)

predict(game_synthetic_1080p_model, newdata = data.frame("tflop" = 12328.65, type = "response"))
177/127

predict(game_synthetic_1600p_model, newdata = data.frame("tflop" = 12328.65, type = "response"))
226/127
```